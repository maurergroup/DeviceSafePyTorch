{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "southeast-blair",
   "metadata": {},
   "source": [
    "\n",
    "# Writing Device Safe PyTorch Code for Fun and Profit\n",
    "Adam McSloy, 2021, Version 0.1\n",
    "\n",
    "## Initialisation\n",
    "Note that a CUDA compliant device, i.e. a Nvidia GPU, is required to execute much of the code present in this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dietary-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemError('No CUDA device found: A CUDA enabled GPU is required for this workbook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-spell",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This document aims provide a very simple introduction to writing \"*device safe*\" PyTorch code. When possible, PyTorch code should be made *device-safe* if it is intended to be executed across multiple, possibly heterogeneous, devices. Generally, it is advised to ensure that any non-trivial code that is intended to be run on a non-CPU device should be made device-safe. However, device safe code is not necessary if executing exclusively on the CPU.\n",
    "\n",
    "Within the context of this document, the term \"*device safe*\" is used to embody three main concepts: **device consistency**, which is the idea that a function's outputs should be on the same device as its inputs; **device purity**, interactions between tensors on different devices should be avoided; and finally **device agnosticism**, results of a function should not depend on the device on which it was ran. It should be noted that these are only general rules, and that many exceptions exist.\n",
    "\n",
    "This document is intended to act only as a initial introduction to the writing of device safe code with PyTorch, users are encouraged to consult the PyTorch documentation for a more in-depth guide. \n",
    "\n",
    "## PyTorch Devices\n",
    "PyTorch has been designed in such a way that it allows the user to specify what device each individual tensor is placed on. This flexibility permits complex operations to be spread out over multiple devices (GPUs/CPUs), which can significantly increase performance. When a `torch.tensor` is initialised without specifying a device to placed it on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "informative-entertainment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"new_tensor\" was placed on device: cpu\n"
     ]
    }
   ],
   "source": [
    "new_tensor = torch.rand(4)\n",
    "print(f'\"new_tensor\" was placed on device: {new_tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-following",
   "metadata": {},
   "source": [
    "then it is placed on the `default` device, which is normally the CPU. The keyword argument \"`device`\" can be used to tell PyTorch which device is responsible for that tensor. This keyword expects a `torch.device` as its input, some examples of which have been provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "automatic-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU = torch.device('cpu')  # <- Device representing the cpu\n",
    "GPU = torch.device('cuda:0')  # <- Device representing the first gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-facial",
   "metadata": {},
   "source": [
    "Which can be used to identify the device to create a new tensor on, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intermediate-place",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"cpu_tensor\" was placed on device: cpu\n",
      "\"gpu_tensor\" was placed on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "cpu_tensor = torch.rand(10, device=CPU)\n",
    "gpu_tensor = torch.rand(10, device=GPU)\n",
    "print(f'\"cpu_tensor\" was placed on device: {cpu_tensor.device}')\n",
    "print(f'\"gpu_tensor\" was placed on device: {gpu_tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-david",
   "metadata": {},
   "source": [
    "PyTorch currently supports nine different device architectures:\n",
    "1. **cpu**: Central Processing Unit (Default).\n",
    "2. **cuda**: Compute Unified Device Architecture (a Nvidia GPU).\n",
    "3. **mkldnn**\n",
    "4. **opengl**\n",
    "5. **opencl**\n",
    "6. **ideep**\n",
    "7. **hip**\n",
    "8. **msnpu**\n",
    "9. **xla**\n",
    "\n",
    "This document will only focus on the first two: \"cpu\" and \"cuda\" as they are the most common, and most issues are  associated with cross CPU-GPU operations. At the time of writing PyTorch only supports a single CPU socket, but multiple GPUs. That is to say `'cuda:0'`, `'cuda:1'` and `'cuda:2'` will resolve to three different devices (assuming three GPUs are connected) but only `'cpu:0'` is valid (`'cpu:1'` and `'cpu:2'` will raise an error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-liverpool",
   "metadata": {},
   "source": [
    "## Device Safe Coding   \n",
    "For the most part, device agnosticism is enforced by the PyTorch module itself and requires little to no input on the part of the developer to achieve. Nevertheless, unit-tests should still check for agnosticism. Both device consistency and device purity must be explicitly built into the code by the developer. Some examples of functions which fail to uphold these two aforementioned concepts have been given below. It should be noted that these functions are **highly contrived** but are designed this way to highlight the issues associated with non-device safe code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "executed-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_by_identity_matrix_bad(mat: Tensor) -> Tensor:\n",
    "    \"\"\"Multiply a matrix by its identity.\n",
    "\n",
    "    Arguments:\n",
    "        mat: The matrix that is to be multiplied by an identity matrix.  \n",
    "        \n",
    "    Returns:\n",
    "        mat_by_eye: `mat` multiplied by its identity matrix.\n",
    "    \n",
    "    Notes:\n",
    "        This is an example of a non-device pure function.  \n",
    "    \"\"\"\n",
    "    # Create the identity matrix\n",
    "    eye = torch.eye(len(mat))\n",
    "    # Multiply it by `mat` and return the result\n",
    "    return mat @ eye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-drunk",
   "metadata": {},
   "source": [
    "Upon first inspection, there does not seem to be anything overtly wrong with the above function. It even executes without issue when fed a tensor on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "noted-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_input_matrix = torch.rand(10, 10, device=CPU)  # <- This would default to the CPU anyway\n",
    "some_result = multiply_by_identity_matrix_bad(some_input_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-estimate",
   "metadata": {},
   "source": [
    "However, if the input tensor is on any device other than the default (CPU) then a crash is encountered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coordinated-carpet",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for argument #3 'mat2' is on CPU, but expected it to be on GPU (while checking arguments for addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4fece58c7222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msome_input_matrix_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGPU\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# <- Place on the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msome_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiply_by_identity_matrix_bad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_input_matrix_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-b9bd427c519f>\u001b[0m in \u001b[0;36mmultiply_by_identity_matrix_bad\u001b[0;34m(mat)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0meye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Multiply it by `mat` and return the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0meye\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor for argument #3 'mat2' is on CPU, but expected it to be on GPU (while checking arguments for addmm)"
     ]
    }
   ],
   "source": [
    "some_input_matrix_gpu = torch.rand(10, 10, device=GPU)  # <- Place on the GPU\n",
    "some_result = multiply_by_identity_matrix_bad(some_input_matrix_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-algeria",
   "metadata": {},
   "source": [
    "Looking at the error message, it can be seen that PyTorch is not happy that an attempt was made to multiply together two tensors that are on different devices. In this case, the input matrix, `mat`, was on the GPU while the `torch.eye` function created a tensor on the CPU, which was the default device. Such a function is therefore **not** device pure which causes sporadic failures during execution.\n",
    "\n",
    "An example of a non-device consistent function is given below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "strategic-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix_of_ones_bad(mat: Tensor) -> Tensor:\n",
    "    \"\"\"Builds a matrix matching the size of `mat` filled with ones.\n",
    "    \n",
    "    Arguments:\n",
    "        mat: Matrix to act as a template for the `ones` matrix.\n",
    "        \n",
    "    Returns:\n",
    "        ones: A matrix of the same size as `mat` filled with ones.\n",
    "    \n",
    "    Notes:\n",
    "        This is a rather contrived function but it is designed to highlight the\n",
    "        issues associated with non-device consistent functions.     \n",
    "    \"\"\"\n",
    "    # Build and return the ones matrix\n",
    "    return torch.ones(mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-potato",
   "metadata": {},
   "source": [
    "Again, the above function looks fine at first glance, and even runs without *apparent* issue on both CPU (default device) and GPU (non-default device) tensors alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "separate-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix_cpu = torch.rand(5, 5, device=CPU)\n",
    "input_matrix_gpu = torch.rand(5, 5, device=GPU)\n",
    "result_matrix_cpu = build_matrix_of_ones_bad(input_matrix_cpu)\n",
    "result_matrix_gpu = build_matrix_of_ones_bad(input_matrix_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-warren",
   "metadata": {},
   "source": [
    "However, upon closer inspection it can be seen that the results are on the cpu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "simplified-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"result_matrix_cpu\" is on the cpu (should be cpu)\n",
      "\"result_matrix_gpu\" is on the cpu (should be cuda:0)\n"
     ]
    }
   ],
   "source": [
    "print(f'\"result_matrix_cpu\" is on the {result_matrix_cpu.device} (should be {CPU})')\n",
    "print(f'\"result_matrix_gpu\" is on the {result_matrix_gpu.device} (should be {GPU})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-wayne",
   "metadata": {},
   "source": [
    "While this may not seem significant it can have serious implications; as it would likely result in the next operation failing due to the result being on an unexpected device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "persistent-practice",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for argument #3 'mat2' is on CPU, but expected it to be on GPU (while checking arguments for addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c82657218bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_matrix_cpu\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mresult_matrix_cpu\u001b[0m  \u001b[0;31m# <- is fine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_matrix_gpu\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mresult_matrix_gpu\u001b[0m  \u001b[0;31m# <- crashes as the result is on a different device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor for argument #3 'mat2' is on CPU, but expected it to be on GPU (while checking arguments for addmm)"
     ]
    }
   ],
   "source": [
    "input_matrix_cpu @ result_matrix_cpu  # <- is fine\n",
    "input_matrix_gpu @ result_matrix_gpu  # <- crashes as the result is on a different device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-overall",
   "metadata": {},
   "source": [
    "At the very least all subsequent code would then be executed the default device, rather than that what the user specified (e.g. the GPU). Which may greatly reduce performance and generally cause a lot of headaches. So the question now becomes what is the most effective way to resolve these issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-coordinator",
   "metadata": {},
   "source": [
    "### The (Subjectively) \"Wrong\" Way\n",
    "The quickest and easiest way to \"fix\" this would be to simply change the default device like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fewer-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-spyware",
   "metadata": {},
   "source": [
    "Now, all new tensors will be created on the GPU by default. While this permits the above functions to operate on GPU tensors without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "attempted-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_matrix_gpu is now on the cuda:0 (should be cuda:0)\n"
     ]
    }
   ],
   "source": [
    "some_input_matrix_gpu = torch.rand(10, 10, device=GPU)  # <- Place on the GPU\n",
    "some_result = multiply_by_identity_matrix_bad(some_input_matrix_gpu)\n",
    "input_matrix_gpu = torch.rand(5, 5, device=GPU)\n",
    "result_matrix_gpu = build_matrix_of_ones_bad(input_matrix_gpu)\n",
    "print(f'result_matrix_gpu is now on the {result_matrix_gpu.device} (should be cuda:0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-submission",
   "metadata": {},
   "source": [
    "However, this has an unintended side-effect in that a crash is now encountered when attempting to run the above functions on CPU tensors. This is because the root cause of the problem was not fixed, but rather moved about. This may work if intending to use the GPU exclusively, however this will fail just about everywhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "commercial-database",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b3ca72dbcaed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msome_input_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCPU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msome_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiply_by_identity_matrix_bad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_input_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-b9bd427c519f>\u001b[0m in \u001b[0;36mmultiply_by_identity_matrix_bad\u001b[0;34m(mat)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0meye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Multiply it by `mat` and return the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0meye\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)"
     ]
    }
   ],
   "source": [
    "some_input_matrix = torch.rand(10, 10, device=CPU)\n",
    "some_result = multiply_by_identity_matrix_bad(some_input_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-scale",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "occupied-highlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"result_matrix_cpu\" is on the cuda:0 (should be cpu)\n"
     ]
    }
   ],
   "source": [
    "input_matrix_cpu = torch.rand(5, 5, device=CPU)\n",
    "result_matrix_cpu = build_matrix_of_ones_bad(input_matrix_cpu)\n",
    "print(f'\"result_matrix_cpu\" is on the {result_matrix_cpu.device} (should be cpu)')\n",
    "torch.set_default_tensor_type(torch.FloatTensor)  # <- Reset default to cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-surface",
   "metadata": {},
   "source": [
    "Similar issues would also be likely when using multiple GPUs. Clearly a more elegant solution is required.\n",
    "### The \"Right\" Way\n",
    "Thankfully the solution to this problem is rather simple. All that is required is to ensure that any new tensors created within a function are placed on the same device as the inputs, see the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "indirect-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again these functions are highly contrived examples that would never actually\n",
    "# be seen in the real world!\n",
    "\n",
    "def multiply_by_identity_matrix_good(mat: Tensor) -> Tensor:\n",
    "    \"\"\"Multiply a matrix by its identity.\n",
    "\n",
    "    Arguments:\n",
    "        mat: The matrix that is to be multiplied by an identity matrix.  \n",
    "        \n",
    "    Returns:\n",
    "        mat_by_eye: `mat` multiplied by its identity matrix. \n",
    "    \"\"\"\n",
    "    # Create the identity matrix\n",
    "    eye = torch.eye(len(mat), device=mat.device)  # <- Change is here!\n",
    "    # Multiply it by `mat` and return the result\n",
    "    return mat @ eye\n",
    "\n",
    "def build_matrix_of_ones_good(mat: Tensor) -> Tensor:\n",
    "    \"\"\"Builds a matrix matching the size of `mat` filled with ones.\n",
    "    \n",
    "    Arguments:\n",
    "        mat: Matrix to act as a template for the `ones` matrix.\n",
    "        \n",
    "    Returns:\n",
    "        ones: A matrix of the same size as `mat` filled with ones.    \n",
    "    \"\"\"\n",
    "    # Build and return the ones matrix\n",
    "    return torch.ones(mat.shape, device=mat.device)  # <- Change is here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-welsh",
   "metadata": {},
   "source": [
    "The above functions now operate without issue. It should be noted that indexing tensors are technically exempt form the \"don't mix device types\" rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "weird-ownership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 3., 5.])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor([1.0,2.0, 3.0, 4.0, 5.0], device=CPU)\n",
    "indices = torch.tensor([0, 2, 4], device=GPU)\n",
    "print(data[indices])  #  <- This does NOT crash as one might expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-attitude",
   "metadata": {},
   "source": [
    "Nevertheless, it is strongly advised to try and keep them on the same device for performance reasons.\n",
    "### Moving Things About\n",
    "Once a tensor has been created it can be \"*moved*\" from one device to another using its `to` method like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "prepared-receiver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"cpu_tensor_moved\" is on the cuda:0\n"
     ]
    }
   ],
   "source": [
    "cpu_tensor = torch.rand(4, device=CPU)  # <- create on the CPU\n",
    "cpu_tensor_moved = cpu_tensor.to(GPU)  # <- make a copy on the GPU\n",
    "print(f'\"cpu_tensor_moved\" is on the {cpu_tensor_moved.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-suffering",
   "metadata": {},
   "source": [
    "It is important to note that the '.to' operation does not actually \"*move*\" the tensor, but rather creates a new copy on the specified device. This means that changes to the original tensor will not propagate to the new tensor, i.e. they do not share the same underling memory reference. For the most part, such operations should be limited to the end points of a code, i.e. the initial set up before running a calculation and the final collection of results. This is because moving information from the CPU to the GPU and vise versa will impact overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-creation",
   "metadata": {},
   "source": [
    "## Unit-Testing\n",
    "This section gives some hints on how unit-tests should be constructed to best test for issues that may occur when trying to develop a device safe project. This assumes that PyTest testing framework is used.\n",
    "\n",
    "### Setup\n",
    "To start with, the following code should be appended to the `conftest.py` configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "final-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import torch\n",
    "\n",
    "\n",
    "def pytest_addoption(parser):\n",
    "    parser.addoption(\n",
    "        \"--device\", action=\"store\", default=\"cpu\", help=\"specify test device (cpu/cuda/etc.)\"\n",
    "    )\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def device(request) -> torch.device:\n",
    "    \"\"\"Defines the device on which each test should be run.\n",
    "\n",
    "    Returns:\n",
    "        device: The device on which the test will be run.\n",
    "\n",
    "    \"\"\"\n",
    "    device_name = request.config.getoption(\"--device\")\n",
    "    if device_name == 'cuda':\n",
    "        return torch.device('cuda:0')\n",
    "    else:\n",
    "        return torch.device(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-water",
   "metadata": {},
   "source": [
    "The first function, `pytest_addoption`, adds a new optional argument, \"`device`\", to the `pytest` command line interface. This new argument allows for the user to specify what device the test is to be run on. For example:\n",
    "```bash\n",
    "pytest --device cpu\n",
    "```\n",
    "\n",
    "would run all tests on the CPU and\n",
    "\n",
    "```bash\n",
    "pytest --device cuda\n",
    "```\n",
    "would run all tests on the GPU. Note that if a device is not specified then it will default to `cpu`. The second function sets up a `pytest.fixture`, more information about fixtures can be found [here](docs.pytest.org/en/stable/fixture.html). In short, a fixture is a device designed to allow variables to be passed into test functions at run-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "contrary-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture\n",
    "def an_example_fixture():\n",
    "    return 10\n",
    "\n",
    "def test_function_example(an_example_fixture):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-atlas",
   "metadata": {},
   "source": [
    "If PyTest was run on the above code, it would save the result of the fixture function \"`an_example_fixture`\", and would then feed that result into any test function which takes an argument of the same name, e.g. the `test_function_example` function. For device testing only one fixture is needed, \"device\". This allows the device to be passed in to the test functions as needed.  \n",
    "\n",
    "These two functions allow for tests to be run easily on any device desired without having to: i) hard code the device; ii) write a separate test for each device; or iii) loop over all devices, all of which would be incredibly inefficient.\n",
    "\n",
    "### Testing\n",
    "It is important to ensure that the test functions actually run on the correct device, as specified by the user. This is best done by manually specifying the device on which each tensor is created, using the `device` fixture like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "built-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_function(device):\n",
    "    x = torch.tensor([1., 2., 3.], device=device)\n",
    "    y = torch.tensor([4., 5., 6.], device=device)\n",
    "    z = my_function(x, y)\n",
    "    ...\n",
    "    ...\n",
    "    # A check would be performed here to check that\n",
    "    # z is within permitted tolerance limits. \n",
    "    ...\n",
    "    ...\n",
    "    device_check = z.device == device\n",
    "    assert device_check, 'Device persistence check'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-banana",
   "metadata": {},
   "source": [
    "Thus, most if not all test functions should make use of the `device` fixture argument. To test for device consistency a short check should be performed at the end of every test to ensure the result has not slipped off the device.\n",
    "\n",
    "\n",
    "Running such tests once on the CPU and again on the GPU should be enough to ensure device-safe code execution as: non-device-agnostic code would result in the tolerance check failing; non-device-pure code would result in an execution error; and non-device-consistent code would fail the `assert device_check` check."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
